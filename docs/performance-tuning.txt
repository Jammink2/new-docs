# Performance Tuning

## Prerequisites

  * Basic knowledge of Treasure Data, including [the toolbelt](http://toolbelt.treasure-data.com).
  * Basic knowledge of [the Hive query language](hive).

## Leveraging Time-based Partitioning

All imported data is automatically partitioned into hourly buckets, based on the **'time'** field within each data record. **By specifying the time range to query, you avoid reading unnecessary data and can thus speed up your query significantly.**

### 1) WHERE time <=> Integer

**When the 'time' field within the WHERE clause is specified**, the query parser will automatically detect which partition(s) should be processed. Please note that this auto detection will not work *if you specify the time with `float` instead of `int`.*

    :::sql
    [GOOD]: SELECT field1, field2, field3 FROM tbl WHERE time > 1349393020
    [GOOD]: SELECT field1, field2, field3 FROM tbl WHERE time > 1349393020 + 3600
    [GOOD]: SELECT field1, field2, field3 FROM tbl WHERE time > 1349393020 - 3600
    [BAD]:  SELECT field1, field2, field3 FROM tbl WHERE time > 1349393020.00

### 2) TD_TIME_RANGE

**An easier way to slice the data is to use [TD_TIME_RANGE UDF](udfs#tdtimerange)**.

    :::sql
    SELECT ... WHERE TD_TIME_RANGE(time, "2013-01-01 PDT")
    SELECT ... WHERE TD_TIME_RANGE(time, "2013-01-01", NULL, "PDT")
    SELECT ... WHERE TD_TIME_RANGE(time, "2013-01-01",
                                   TD_TIME_ADD("2013-01-01", "1day", "PDT"))

## Set Custom Schema

As explained in [the "Schema Management" article](schema), all tables have two fields: 'v' and 'time'. In addition to these, you can set [custom schema](schema#setting-custom-schema) on the tables.

    :::term
    $ td schema:set testdb www_access action:string user:int
    $ td query -w -d testdb "SELECT user, COUNT(1) AS cnt
         FROM www_access
         WHERE action='login'
         GROUP BY user ORDER BY cnt DESC"

After setting the schema, **queries issued with named columns instead of 'v'** will use the schema information to achieve a more optimized execution path. In particular, GROUP BY performance will improve significantly.

## Use Hive's Mapjoin

If all but one of the tables being joined are small, Hive can perform the join on the mapper side in memory. This can greatly reduce the query time by cutting down on the number of mappers and/or stages in the mapreduce pipeline.

    :::sql
    SELECT /*+ MAPJOIN(tbl2) */ ... FROM tbl1 join tbl2 on tbl1.key = tbl2.key

In this example, we're specifying `b` as a Mapjoin table, meaning it is much smaller compared to `a` and should fit in memory. For more information on this optimization, please refer to the [Hive documentation](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Joins#LanguageManualJoins-Mapjoinrestrictions)

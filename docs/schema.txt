# Schema Management

Treasure Data uses the same analogy with RDBMSs for managing data sets: *Database* and *Table*. Also *Schema* can be associated to the tables. Unlike traditional warehousing platforms, Treasure Data takes the store-first, schema-later approach. The schema changes are done at anytime, with no cost.

## Prerequisites

  * Basic knowledge of Treasure Data, including the latest installed version of the toolbelt.

Also need the table, which has some data. Please refer [Getting Started](quickstart) to create db/table and import the data in it.

## Schema Changes Are The Pain

Most conventional warehousing platforms are schema dependent, supporting an **assumptive** analytics model. In this model, data elements forecasted to yield insights are defined in advance, as well as structure of the data store schema.

Performance considerations are also important in initial design and the analyst must have knowledge of the underlying structure to insure query performance. When new columns are added to the table, the schema must need to be changed.

Big Data analysis however, is largely **non-assumptive**. The analyst seeks hidden patterns, relationships or events in the data that were not intuitively obvious from the outset. The user must be able to query where the data takes him without the burden of performance considerationsâ€”and exploration can create requirements for new records to support the analysis trail.

In this model schema dependence adds a significant tax that can become prohibitive.

## Store-First, Schema-Later Approach

Unlike traditional warehousing platforms, TD's schema is given even after importing the data. This means you can add/remove the fields at any moment. It's done in a moment, not in days.

## Default Schema (time and v)

Just after you've created the table, it has two fields:

* *time*: int64 UNIX time, which represents generated time
* *v*: map<string, string>, which represents each log entry

When you refer the value, you need to specify like *v['field1']*. Also the type of *v* is fixed as map<string, string>, so all the values are treated as *String*. To treat the value as other types, the casting is required.

## Setting Custom Schema

In general, you're ok with a default schema, and no need to set a custom schema here. But having the custom schema, you can get more shorter query, and performance benefits (up to 30%). You can set the schema to the table via `td schema:set` command.

    :::term
    $ td schema:set <database> <table> <column_name>:<type>...

Consider if we have a table which contains the `user` (int type) and `action` (string type) column, adding the schema is like follows.

    :::term
    $ td schema:set testdb www_access action:string user:int

Then you can query into that table, without using *v*.

    :::term
    $ td query -w -d hoge "SELECT user, COUNT(*) AS cnt
      FROM www_access
      WHERE action='login'
      GROUP BY user ORDER BY cnt DESC"

Using *v* still works properly.

    :::term
    $ td query -w -d testdb "SELECT v['user'], COUNT(*) AS cnt
     FROM www_access
     WHERE v['action']='login' 
     GROUP BY v['user'] ORDER BY cnt DESC"


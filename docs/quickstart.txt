Quickstart Guide
================

Let's Get Started with Treasure Data. Treasure Data is a **cloud-based data warehousing** service. Forget about servers, storages, and infrastructure while storing billions of records and focus on your data analytics.

No special know-how is required: Just import JSON-based records into our cloud data warehouse, and process them by SQL queries.

Let's get started.

Step 1: Sign-Up
---------------

Sign-up for Treasure Data, unless you already have one.

Step 2: Install Treasure Data Toolbelt
------------------------------------------

Install the [Treasure Data Toolbelt](http://treasure-data.com/toolbelt.html) for your development environment.

The toolbelt contains 'td' command, a [CLI tool](/categories/command-line) for importing, managing, and issueing a query on your data.

Step 3: Authorize
-----------------

After installing the toolbelt, you'll have access to td command from your command line shell. Please authorize your account by *td account* by using an emaill address and password you used when creating your account:

    :::term
    $ td account -f
    User name: k@example.com
    Password (typing will be hidden): 
    Authenticated successfully.

Step 4: Import Sample Dataset
-----------------------------

Now you're ready! Typically, our service is used to store massive event data and logs. So let's start importing Apache log sample dataset. At first, you need to create the database and table on the cloud, by CLI.

    :::term
    $ td db:create testdb
    $ td table:create testdb www_access
    $ td tables
    +------------+------------+------+-----------+
    | Database   | Table      | Type | Count     |
    +------------+------------+------+-----------+
    | testdb     | www_access | log  | 0         |
    +------------+------------+------+-----------+

Then, let's generate sample Apache logs data and import it to the cloud. 'td sample:apache' commands generates 5,000 lines of a JSON file, which contains exactly same information with Apache logs. 'td table:import' takes JSON file, and uploads.

    :::term
    $ td sample:apache apache.json
    $ td table:import testdb www_access --json apache.json
    $ tail -n 1 apache.json
    {"host":"200.129.205.208","user":"-","method":"GET","path":"/category/electronics","code":200,"referer":"-","size":62,"agent":"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11","time":1334035906}

After several seconds, the records will be imported into our database.

    :::term
    $ td tables
    +------------+------------+------+-----------+
    | Database   | Table      | Type | Count     |
    +------------+------------+------+-----------+
    | testdb     | www_access | log  | 5000      |
    +------------+------------+------+-----------+

Step 5: Issue Queries
-----------------------

Finally, let's issue a SQL query. The query is executed with Hadoop-based engine on the cloud. Only its result is returned back to you. Here's a query to calculate the distribution of HTTP status codes.

NOTE: You may be surprise that this takes around <b>15 seconds</b>. This is the overhead of setting up the jobs within the cloud based on Hadoop framework. Typically a query takes several minutes.

    :::term
    $ td query -w -d testdb \
      "SELECT v['code'], COUNT(1) FROM www_access GROUP BY v['code']"
    queued...
    started at 2012-04-10T23:44:41Z
    2012-04-10 23:43:12,692 Stage-1 map = 0%,  reduce = 0%
    2012-04-10 23:43:18,766 Stage-1 map = 100%,  reduce = 0%
    2012-04-10 23:43:29,925 Stage-1 map = 100%,  reduce = 33%
    2012-04-10 23:43:32,973 Stage-1 map = 100%,  reduce = 100%
    Status     : success
    Result     :
    +------+------+
    | code | cnt  |
    +------+------+
    | 200  | 4981 |
    | 404  | 17   |
    | 500  | 2    |
    +------+------+

Step 6: Logging from Your Application
-------------------------------------

Now it's turn to import your actual data to the cloud. See the following tutorials to learn how to import your data, using a supported languages, frameworks, or middleware:

  * Languages and Frameworks
    * [Java](java)
    * [Ruby](ruby) or [Rails](rails)
    * [Python](python)
    * [PHP](php)
    * [Perl](perl)
    * [Node.js](nodejs)
    * [Scala](scala)
  * Middleware
    * [Apache Logs](apache)


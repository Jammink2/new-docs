# Data Import from Scala Applications

In order to import data from Scala applications to Treasure Data, we provide a logger library called '[td-logger-java](http://github.com/treasure-data/td-logger-java/)'. This article describes how to use that library.

## Prerequisites

  * Basic knowledge of Scala
  * Basic knowledge of Treasure Data, including the latest installed version of [the toolbelt](http://toolbelt.treasure-data.com).
  * An installed version of JVM, Scala, [sbt](https://github.com/harrah/xsbt) v0.11 or later.

NOTE: Scala users, please look at <a href="/articles/heroku-java">Java Apps on Heroku</a>.

## Install the td-agent

At first, you need to setup `td-agent` on your application servers. `td-agent` is a daemon program dedicated to the continuous upload of any kind of streaming log data. td-agent is developed and maintained by Treasure Data, Inc.

<center><img src="/images/td-agent-app.png" width="90%" /></center><br /><br />

Through [td-logger-java](http://github.com/treasure-data/td-logger-java/) library, Scala applications can post their application logs to local td-agent, and it uploads to the cloud every 5 minutes. Because the daemon runs on a local node, the logging latency is negligible.

Please refer to the following articles in setting up td-agent. For Linux systems, we're providing deb/rpm packages for the easy installation.

<table>
  <tr>
    <th>If you have...</th>
    <th>Please look at...</th>
  </tr>
  <tr>
    <td>Debian / Ubuntu System</td>
    <td><a href="http://treasure-data.tenderapp.com/kb/installing-td-agent-daemon/installing-td-agent-for-debian-and-ubuntu">Installing td-agent for Debian and Ubuntu</a></td>
  </tr>
  <tr>
    <td>Redhat / CentOS System</td>
    <td><a href="http://treasure-data.tenderapp.com/kb/installing-td-agent-daemon/installing-td-agent-for-redhat-and-centos">Installing td-agent for Redhat and CentOS</a></td>
  </tr>
</table>

NOTE: Please note that td-agent is fully open-sourced as the <a href="http://github.com/fluent/">fluentd project</a>. td-agent is a package which contains fluentd and extension plugins for Treasure Data.

## Modify /etc/td-agent/td-agent.conf

We’ll also need to set the `apikey` option, which is a secret key to authenticate our account. Our api key can be shown by `td apikey:show`, as long as we have successfully authenticated our account using the `td account` command.:

    :::term
    $ td apikey:show
    3b7118fd3ad7e35bbd3c0e4f607ec7263aa93c30

Let’s set the `apikey` option in our td-agent.conf file. Please replace `YOUR_API_KEY` to your actual apikey string.

    :::term
    # Treasure Data Input and Output
    <source>
      type forward
      port 24224
    </source>
    <match td.*.*>
      type tdlog
      apikey YOUR_API_KEY
      auto_create_table
      buffer_type file
      buffer_path /var/log/td-agent/buffer/td
    </match>

Once these lines are in place, we’ll restart our agent.

    :::term
    $ sudo /etc/init.d/td-agent restart

We have now enabled td-agent to read, and upload our log data into the cloud via port 24224.

## Use fluent-logger-java

[td-logger-java](http://github.com/treasure-data/td-logger-java/) is a Java library to record events to td-agent from a Scala application. At first, please add those lines to your build.sbt. Please find the latest version number from [CHANGES.txt](https://github.com/treasure-data/td-logger-java/blob/master/CHANGES.txt).

NOTE: If you need a all-in-one jar file, please download from <a href="http://treasure-data.com/maven2/">http://treasure-data.com/maven2/</a>.

    :::scala
    /* in build.sbt */
    // Repositories
    resolvers ++= Seq(
      "td-logger     Maven2 Repository" at "http://treasure-data.com/maven2/",
      "fluent-logger Maven2 Repository" at "http://fluentd.org/maven2/"
    )
    // Dependencies
    libraryDependencies ++= Seq(
      "com.treasure_data" % "td-logger" % "${logger.version}"
    )

Then, please prepare your `treasure-data.properties` file.

    :::term
    td.logger.agentmode=true
    td.logger.agent.host=localhost
    td.logger.agent.port=24224

Finally, please initialize and post the records as follows.

    :::scala
    import java.util.Properties
    import com.treasure_data.logger.TreasureDataLogger
    import scala.collection.JavaConverters._

    object Main {
      def main(args: Array[String]) {
        var props = System.getProperties();
        props.load(getClass.getResourceAsStream("treasure-data.properties"));
        var LOG = TreasureDataLogger.getLogger("my_database");
    
        var map = Map("from" -> "userA", "to" -> "userB");
        LOG.log("follow", map.asJava.asInstanceOf[java.util.Map[String, java.lang.Object]]);
      }
    }

## Confirm the Import

The posted records are first transferred to the local td-agent. td-agent buffers the records within local disk for a while, and uploads them every 5 minutes.

NOTE: The first argument of post() determines the database name and table name. If you specify 'td.test_db.test_table', the data will be imported into *test_table* table within *test_db* database. Those are automatically created at the upload time.

Rather than waiting 5 minutes, sending SIGUSR1 signal to the agent flushes its buffe,r and it starts uploading immediately.

    :::term
    $ sbt compile run
    $ kill -USR1 `cat /var/run/td-agent/td-agent.pid`

To confirm the data upload, please use `td tables`.

    $ td tables
    +------------+------------+------+-----------+
    | Database   | Table      | Type | Count     |
    +------------+------------+------+-----------+
    | test_db    | test_table | log  | 1         |
    +------------+------------+------+-----------+

## Production Deployments

### High-Availablability Configurations of td-agent

For highly loaded sites (more than 5 application nodes), we recommend using high availability configuration for td-agent. This improves the data transfer reliability, and also the query performance.

* [High-Availability Configurations of td-agent](td-agent-high-availability)

## Next Step

Next, you may be curious about our schema mechanism, which is completely different from traditional RDBMSs. Also, please look at HiveQL section to know more about queries.

* [Schema Management](/articles/schema)
* [Hive Query Language](http://localhost:9393/articles/hive)

For more specific assistance, please visit our support resources:

* [Treasure Data Discussion Forum](http://help.treasure-data.com/)

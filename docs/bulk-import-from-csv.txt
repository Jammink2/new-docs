# Bulk Import from CSV file

This article explains how to import data from CSV files to Treasure Data.

## Install Bulk Loader

First, please install the [toolbelt](command-line), which includes bulk loader program, on your computer.

#### Downloads
- [Toolbelt Installer for Windows](http://toolbelt.treasuredata.com/win)
- [Toolbelt Installer for Mac OS X](http://toolbelt.treasuredata.com/mac)
- [Toolbelt Installer for Linux](http://toolbelt.treasuredata.com/linux)

After the installation, `td` command will be installed on your computer. Please open up the terminal, and type `td` to execute the command. Also, please make sure you have `java` as well. Please execute `td import:jar_update` to download the up-to-date version of our bulk loader.

    :::term
    $ td
    usage: td [options] COMMAND [args]
    $ java
    Usage: java [-options] class [args...]
    $ td import:jar_update
    Installed td-import.jar 0.x.xx into /path/to/.td/java

## Importing data from a CSV

Suppose you have a file called `data.csv` and its content is like this:

    :::term
    $ head -n 5 data.csv
    "host","log_name","date_time","method","url","res_code","bytes","referer","user_agent"
    "64.242.88.10","-","2004-03-07 16:05:49","GET","/twiki/bin/edit/Main/Double_bounce_sender?topicparent=Main.ConfigurationVariables",401,12846,"",""
    "64.242.88.10","-","2004-03-07 16:06:51","GET","/twiki/bin/rdiff/TWiki/NewUserTemplate?rev1=1.3&rev2=1.2",200,4523,"",""
    "64.242.88.10","-","2004-03-07 16:10:02","GET","/mailman/listinfo/hsdivision",200,6291,"",""
    "64.242.88.10","-","2004-03-07 16:11:58","GET","/twiki/bin/view/TWiki/WikiSyntax",200,7352,"",""

Next, please execute the following commands to upload the CSV file.

    $ td db:create sampledb
    $ td table:create sampledb sampletbl
    $ td import:auto \
      --format csv --column-header \
      --time-column date_time \
      --time-format "%Y-%m-%d %H:%M:%S" \
      --auto-create sampledb.sampletbl \
      ./data.csv

NOTE: Because `td import:auto` executes the MapReduce jobs to check the invalid rows, it'll take at least <b>1-2 minutes</b>.

In the above command, we assumed that:

* The data file is called `data.csv` and is located in the current directory (hence `./data.csv`)
* The first line indicates column names
* The time field is called "date_time"
* The time format is %Y-%m-%d %H:%M:%S (You can specify your own with `--time-format`)

For further details, check the following documentations.

- [Bulk Import Internals](bulk-import-internal).
- [Bulk Import Tips and Tricks](bulk-import-tips-and-tricks)

# Writing Query Results into AWS Redshift

This article explains how to write job results to your existing Amazon Redshift cluster.

## Prerequisites

  * Basic knowledge of Treasure Data, including the [toolbelt](http://toolbelt.treasuredata.com);
  * An **Amazon Redshift cluster** setup and running - either a single or multi node cluster;
  * At least 'Query only' privileges to the Treasure Data table to be queried.

## Architecture

A front-end application streams data to be collected in Treasure Data via [Treasure Agent](td-agent). Treasure Data periodically runs jobs on the data, then writes the job results to your Redshift cluster.

<center><img src="/images/result_xyz.png" width="100%" /></center><br /><br />

NOTE: The results are written from the AWS US-East region. If you want better security control, please message support@treasure-data.com and ask for its account ID and security group name.

The one depicted above is a fairly common architecture which then enables data analysts well versed in using Redshift to focus on their queries and visualizations without having to worry about how the data gets uploaded there.

## Amazon Redshift configuration

Amazon Redshift can be configured in single node mode or multi node/cluster mode. The multi node configuration provides more query computation power by means of parallelization of the query execution on the available nodes.

## Result Output URL

### Format

The result output target is represented by URL with the following format:

    :::term
    redshift://<username>:<password>@<hostname>:<port>/<database>/<table>

where:

* **redshift** is identified for result output to Redshift;
* **username** and **password** are the credential to the Amazon Redshift instance. These credentials are specified when first creating the Redshift
cluster and they are different from the S3 public/private access keys;
* **hostname** can be retrieved from the Redshift configuration page: typically it has this format \<name\>.\<instance_id\>.\<region\>.redshift.amazonaws.com. The name is the one provided for the cluster, the instance id is auto generated by Amazon Redshift upon creation of the cluster, the region is the Amazon availability zone of choice;
* the **port** number is fixed to 5439 for single node clusters. It may vary for multi node cluster configuration and the actual value can be retrieved from the Redshift cluster detail page;
* **database** is the name of the database specified at the creation of the Redshift cluster. It can be retrieved from the Redshift cluster detail page;
* **table** is the name of a table within the above mentioned database. It may not exist at the moment the query output is execute, in which case a table with the specified name will be created for the user.

### Options

Since interacting with a Redshift instance is done through either a JDBC or ODBC Postgres driver, result output to redshift supports the same options [result output to Postgres](result-into-postgresql#result-ouput-url) does.

## Usage

Only the CLI supports query result output to Redshift at the moment.

### CLI

To output the result of a single query to Amazon Redshift add the `--result` option to the `td query` command. After the job is finished, the results will be written into your instance.

    :::term
    $ td query -w -d testdb \
      --result 'redshift://username:password@host.redshift.amazonaws.com:5439/database/table' \
      "SELECT v['code'], COUNT(1) FROM www_access GROUP BY v['code']"

To create a scheduled query whose output is systematically written to Redshift add the `--result` option when creating the schedule using the `td sched:create` command:

    :::term
    $ td sched:create hourly_count_example "0 * * * *" -d testdb \
      --result 'redshift://username:password@host.redshift.amazonaws.com:5439/database/table' \
      "SELECT COUNT(*) FROM www_access"


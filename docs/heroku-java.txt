# Java Apps on Heroku

## Data Import

It's a **4 STEP** approach. 1) **Embed** codes, 2) **Run** it, 3) **Check**, and 4) **Query** it.

### Step1: Import Data Using td-logger Library

Please install [td-logger](https://github.com/treasure-data/td-logger-java) library by the procedure described at here. All-in-one jar, Maven2, or custom-build is supported. This is an Maven2 pom.xml example. Please look at [README](https://github.com/treasure-data/td-logger-java/blob/master/README.md) for other installations.

    :::xml
    <dependencies>
      ...
      <dependency>
        <groupId>com.treasure_data</groupId>
        <artifactId>td-logger</artifactId>
        <version>0.1.3</version>
      </dependency>
      ...
    </dependencies>
    <repositories>
      <repository>
        <id>treasure-data.com</id>
        <name>Treasure Data's Maven2 Repository</name>
        <url>http://treasure-data.com/maven2</url>
      </repository>
      <repository>
        <id>fluentd.org</id>
        <name>Fluentd's Maven2 Repository</name>
        <url>http://fluentd.org/maven2</url>
      </repository>
    </repositories>

Finally, please insert the logging code like followings. Further details regarding the event logger API can be found here.

    :::java
    import com.treasure_data.logger.TreasureDataLogger;
    public class Main {
      private static TreasureDataLogger LOG;
      static {
        try {
          Properties props = System.getProperties();
          props.load(Main.class.getClassLoader().getResourceAsStream("treasure-data.properties"));
          LOG = TreasureDataLogger.getLogger("sample_database");
        } catch (IOException e) {
          // do something
        }
      }
      public void doApp() {
        Map<String, Object> data = new HashMap<String, Object>();
        data.put("from", "userA");
        data.put("to", "userB");
        LOG.log("follow", data);
      }
    }

After inserting your event-logging code, push the modifications to Heroku!

    :::term
    $ git commit -a -m "Added Treasure Data Plugin"
    $ git push heroku master

### Step2: Access Your Application

First, open your application on Heroku. The recorded events are first buffered locally, then periodically uploaded into the cloud. In the current implementation, the buffered data is uploaded in 5 minute intervals.

    :::term
    $ heroku open

### Step3: Check Your Uploaded Data

#### Database Structure

Treasure Data Hadoop structures its data much like RDBMS: tables inside databases. In order to see the list of available databases, use the command: ‘heroku td dbs’.

    :::term
    $ heroku td dbs
    +------------------+
    | Name             |
    +------------------+
    | sample_database |
    +------------------+
    1 row in set

#### Checking Your Data

In order to see the tables inside the available databases, use the command: ‘heroku td tables’.

    :::term
    $ heroku td tables
    +------------------+--------+------+-------+--------+
    | Database         | Table  | Type | Count | Schema |
    +------------------+--------+------+-------+--------+
    | sample_database  | follow | log  | 1     |        |
    | sample_database  | pay    | log  | 7     |        |
    +------------------+--------+------+-------+--------+
    2 rows in set

To confirm that your application data has been uploaded properly, please check the ‘Count’ column. If any of the ‘Count’ entries are non-zero, your event logs been transferred successfully.

If your data has been uploaded properly, then use the ‘heroku td table:tail’ command to see the recent entries of a specific table.

    :::term
    $ heroku td table:tail sample_database follow
    {"action":"follow","uid":12345,"from":"TreasureData","to":"heroku","time":1320857514}

### Step4: Analyze Your Data

Our service lets you to analyze your data using a SQL-style language. When your data is sent to us, your logs are imported into a Hadoop/Hive cluster. Hive lets its users query big data through a SQL-like interface.

Please use the ‘heroku td query’ command to issue queries to TD Hadoop; TD Hadoop will accept and execute queries within the cloud.

The example query below counts the number of ‘follow’ actions that were generated by userid 12345:

    :::term
    $ heroku td query -w -d sample_database \
      "SELECT COUNT(1) FROM follow WHERE v['uid']=12345"
    +---+
    | 0 |
    +---+
    | 1 |
    +---+
    1 row in set

The next example query counts the total number of logged actions for each day.

    :::term
    $ heroku td query -w -d sample_database \
      "SELECT to_date(from_unixtime(time)) AS day, count(1) FROM follow GROUP BY to_date(from_unixtime(time)) ORDER BY day"
    +------------+----+
    | 0          | 1  |
    +------------+----+
    | 2011-11-09 | 1  |
    +------------+----+
    1 row in set

The ‘heroku td query –format csv’ command will return the results in csv format.

## Development Environment Setup

Please set `TREASURE_DATA_API_KEY` env variable For development environment.

    :::term
    $ heroku config | grep TREASURE_DATA
    TREASURE_DATA_API_KEY => 2d14b1872cb789ed3733d4aa26ae8e6aba30bbbd
    $ export TREASURE_DATA_API_KEY=2d14b1872cb789ed3733d4aa26ae8e6aba30bbbd

Then, please start an application normally.

## Does Upload Impact the App Performance?

Througth `td-logger` Java library, the posted records are buffered locally at first, and uploads are done every 5 minutes. Because a dedicated thread uploads the data into the cloud, it doesn't affect the response time.

There's also a size limit of the local buffer. If the local data size exceeds that limit, the records start uploaded immediately.

## Next Step

For more specific assistance, please visit our support resources:

* [Treasure Data Discussion Forum](http://help.treasure-data.com/)

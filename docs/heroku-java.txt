# Java Apps on Heroku

## Prerequisites

  * Basic knowledge of Java.
  * Basic knowledge of Heroku, including the Heroku toolbelt.
  * Java 1.6 or higher.

## Data Import

### Step 1: Add the td-logger Library

First, please install [the td-logger library](https://github.com/treasure-data/td-logger-java). All-in-one jar, Maven2, and custom-build are supported. Shown below is an example Maven2 pom.xml file. This [README](https://github.com/treasure-data/td-logger-java/blob/master/README.md) describes the other two methods of installation.

    :::xml
    <dependencies>
      ...
      <dependency>
        <groupId>com.treasure_data</groupId>
        <artifactId>td-logger</artifactId>
        <version>0.1.3</version>
      </dependency>
      ...
    </dependencies>
    <repositories>
      <repository>
        <id>treasure-data.com</id>
        <name>Treasure Data's Maven2 Repository</name>
        <url>http://treasure-data.com/maven2</url>
      </repository>
      <repository>
        <id>fluentd.org</id>
        <name>Fluentd's Maven2 Repository</name>
        <url>http://fluentd.org/maven2</url>
      </repository>
    </repositories>

Let's write some code to start logging from your application. You can find more information about the logger API [here](https://github.com/treasure-data/td-logger-java).

    :::java
    import com.treasure_data.logger.TreasureDataLogger;
    public class Main {
      private static TreasureDataLogger LOG;
      static {
        try {
          Properties props = System.getProperties();
          props.load(Main.class.getClassLoader().getResourceAsStream("treasure-data.properties"));
          LOG = TreasureDataLogger.getLogger("sample_database");
        } catch (IOException e) {
          // error handling here
        }
      }
      public void doApp() {
        Map<String, Object> data = new HashMap<String, Object>();
        data.put("from", "userA");
        data.put("to", "userB");
        LOG.log("follow", data);
      }
    }

That's it! You're now ready to deploy your changes.

    :::term
    $ git commit -a -m "Added Treasure Data Plugin"
    $ git push heroku master

### Step 2: Access Your Application

Next, open your application on Heroku. The recorded events are first buffered locally, then uploaded periodically into the cloud. In the current implementation, the buffered data is uploaded every 5 minutes.

    :::term
    $ heroku open

### Step 3: Check Your Uploaded Data

#### Database Structure

Treasure Data Hadoop's data structure is like RDBMS: tables inside databases. In order to see the list of available databases, use the command: `heroku td dbs`.

    :::term
    $ heroku td dbs
    +------------------+
    | Name             |
    +------------------+
    | sample_database |
    +------------------+
    1 row in set

#### Checking Your Data

In order to see the tables inside the available databases, use the command: `heroku td tables`.

    :::term
    $ heroku td tables
    +------------------+--------+------+-------+--------+
    | Database         | Table  | Type | Count | Schema |
    +------------------+--------+------+-------+--------+
    | sample_database  | follow | log  | 1     |        |
    | sample_database  | pay    | log  | 7     |        |
    +------------------+--------+------+-------+--------+
    2 rows in set

To confirm that your application data has been uploaded properly, check the "Count" column. If any of the "Count" entries are non-zero, your event logs have been transferred successfully.

Once your data has been uploaded properly, use the `heroku td table:tail` command to see the recent entries of a specific table.

    :::term
    $ heroku td table:tail sample_database follow
    {"action":"follow","uid":12345,"from":"TreasureData","to":"heroku","time":1320857514}

### Step 4: Analyze Your Data

You can analyze your data with a Hive-compatible query language. (When your data is sent to Treasure Data Hadoop, your logs are imported into a Hadoop/Hive cluster.)

Use the `heroku td query` command to issue queries to Treasure Data Hadoop; Treasure Data Hadoop accepts and executes queries on the cloud.

The example query below counts the number of "follow" actions that were generated by user id 12345:

    :::term
    $ heroku td query -w -d sample_database \
      "SELECT COUNT(1) FROM follow WHERE v['uid']=12345"
    +---+
    | 0 |
    +---+
    | 1 |
    +---+
    1 row in set

The following example query counts the total number of logged actions for each day.

    :::term
    $ heroku td query -w -d sample_database \
      "SELECT to_date(from_unixtime(time)) AS day, count(1) \
      FROM follow GROUP BY to_date(from_unixtime(time)) ORDER BY day"
    +------------+----+
    | 0          | 1  |
    +------------+----+
    | 2011-11-09 | 1  |
    +------------+----+
    1 row in set

The `heroku td query â€“format csv` command outputs the results in csv.

## Development Environment Setup

In order to use Treasure Data Hadoop, you must set your `TREASURE_DATA_API_KEY` env variable.

    :::term
    $ export TREASURE_DATA_API_KEY=`heroku td apikey:show`

Once it is set, you can start your application as usual.

## Does Upload Impact App Performance?

The td-logger library buffers data locally at first, and the data is uploaded every 5 minutes. Because a dedicated thread uploads the data into the cloud, it doesn't affect your application's response time.

The local buffer also has a size limit. If the local data exceeds this limit, the records will be uploaded immediately.

## Next Steps

The Heroku Addon Notes document explains the limitations of Heroku addons. We recommend that you review this information before moving on to other articles.  

We offer a schema mechanism that is more flexible than that of traditional RDBMSs. For queries, we leverage the Hive Query Language.

* [Heroku Addon Notes](heroku-notes)
* [Schema Management](schema)
* [Hive Query Language](hive)

For more specific assistance, please visit our support resources:

* [Treasure Data Discussion Forum](http://help.treasure-data.com/)
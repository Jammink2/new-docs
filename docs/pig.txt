Pig Latin Language
==================

[Pig Latin](http://pig.apache.org/) is a relational data-flow language built on top of the Hadoop platform. This article explains how to use Pig as a query interface for Treasure Data.

## Prerequisites

  * Basic knowledge of Treasure Data, including [the toolbelt](http://toolbelt.treasure-data.com).

## About Apache Pig

[Pig](http://hive.apache.org/) is a top level project of the Apache foundation. Treasure Data supports Pig as a data processing method (current version: 0.10.0).

## Documentation and References

* [The official Pig documentation](http://pig.apache.org/docs/r0.10.0/) provides an overview of Pig.
* The [Pig Latin Basics](http://pig.apache.org/docs/r0.10.0/basic.html) document covers the basics of Pig syntax and queries.
* The [Comparing Pig and Hive](http://developer.yahoo.com/blogs/hadoop/posts/2010/01/comparing_pig_latin_and_sql_fo/) blog article gives a high level comparison of Hive and Pig.
* The [DataFu](https://github.com/linkedin/datafu) package contains useful UDFs for Pig.

## CLI Usage

You can issue queries using the `td query` command.

    :::term
    usage:
      $ td query -t pig <pig scripts>
    
    example:
      $ td query -d example_db -t pig "OUT = FOREACH (GROUP table1 ALL) GENERATE COUNT(table1);"
    
    options:
      -t, --type TYPE specify the type of query (requires specifying 'pig' in order to issue queries in Pig Latin)
      -q, --query PATH read query from a file instead of inline
      -d, --database DB_NAME use this database (required)
      -w, --wait wait for the job to finish
      -o, --output PATH write results to this file
      -f, --format FORMAT write results to file in this format (tsv, csv, json or msgpack)
      -r, --result RESULT_URL write results to this URL (see also result:create subcommand)
      -u, --user NAME set user name for the result URL
      -p, --password ask for the password for the result URL
      -P, --priority PRIORITY set priority

A pig script often consists of multiple lines, which makes loading scripts from files useful. You can load pig scripts from files using the `-q` parameter as shown below.

    :::term
    $ td query -d example_db -t pig -q pig-script.txt

## Pig on Treasure Data
Because Treasure Data operates on a multi-tenant model with data stored in columnar format, it is unlike typical Hadoop environments. Below is a summary of characteristics unique to the Treasure Data platform:

  * We prepopulate all other scripts with `LOAD` statements that define all tables as variables. For example, if `www_access` is a table in the selected database, then the variable `www_access` is automatically created. You may create further statements referring to this variable, for example `A = GROUP a BY v#'code'`. Since all table load statements are predefined, you do not need any `LOAD`s in your script.
  * `STORE` statements are also not needed. The last declared variable in your script will automatically be saved as the result of your query.
  * For security reasons, the following keywords are not supported: `set`, `cat`, `cd`, `kill`, `ls`, `pwd`, `move`, `copy`, `mkdir`, `remove`, `fs`, `sh`.
  * Pig requires that field and relation names start with a alphabetic character. If your table has fields that start with a numeric character or a symbol, it cannot be processed.


## Example Queries

Here are some basic examples. We will assume that the underlying table consists of three fields: `ip`, `url`, and `time`. The schema on this table is assumed to be unset.

#### Number of records

    :::term
    OUT = FOREACH (GROUP www_access ALL) GENERATE COUNT(www_access);

#### Number of records per unique IP

    :::term
    OUT = FOREACH (GROUP www_access BY v#'ip') GENERATE group AS ip, COUNT(www_access) AS cnt;

#### Number of records per unique IP to the root page

    :::term
    F = FILTER www_access BY v#'url' == '/';
    OUT = FOREACH (GROUP F BY v#'ip') GENERATE group AS ip, COUNT(www_access) AS cnt;

#### Unique IPs sorted by number of accesses

    :::term
    F = FILTER www_access BY v#'url' == '/';
    GROUP = FOREACH (GROUP F BY v#'ip') GENERATE group AS ip, COUNT(www_access) AS cnt;
    OUT = ORDER GROUP BY cnt DESC;

## Parameter Substitution
Parameters are values that are passed in at runtime as substitutes for some variables. We provide some default variables for the scheduled query feature:

`$TD_SCHEDULED_TIME` represents the time when the current query is scheduled to run. Example usage:
  
    :::term
    FILTER www_access BY time > $TD_SCHEDULED_TIME;

## UDFs
The [DataFu](https://github.com/linkedin/datafu) package of Pig UDFs are included in our platform. Please refer to its documentation for usage instructions.

The [Piggybank](http://svn.apache.org/viewvc/pig/trunk/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/) set of UDFs are also included.

To make these UDFs, you either need to specify the fully qualified name or use a define statement as demonstrated in the below examples.

Examples:

    :::term
    FILTER www_access BY org.apache.pig.piggybank.evaluation.IsInt(v#'code');

    :::term
    define IsInt org.apache.pig.piggybank.evaluation.IsInt();
    FILTER www_access BY IsInt(v#'code');